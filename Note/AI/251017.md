# AI 2 - CNN 실습
## MLP의 한계와 CNN의 등장
- MLP는 각 픽셀을 개별적인 특성으로 다루기 때문에, 이미지를 1차원 벡터로 펼쳐서 입력해야 함
- 이 과정에서 이미지의 중요한 공간적 정보, 즉 픽셀 간의 상하좌우 관계가 모두 사라지는 치명적인 단점 존재
- CNN(합성곱 신경망)의 해결책
  - CNN은 이미지를 2차원 형태 그대로 입력받아, 필터라는 도장으로 이미지의 각 부분을 찍어보며 특징을 추출
  - 이를 통해 공간적 정보를 유지하며 이미지의 패턴(선, 모서리, 질감 등)을 효과적으로 학습할 수 있음
- 이미지 데이터를 MLP(완전 연결방식)만으로 구현할 경우
  - 완전연결층 기반의 순방향 MLP에서는 1차원으로 변형되어 2차원 행렬 성질(이미지의 공간구조)이 반영되지 못함
# CNN 실습
## 파이프라인
1. 데이터 준비: torchvision을 사용해 CIFAL-10 이미지 데이터셋을 불러오고, 모델이 학습하기 좋은 형태로 전처리(정규화)
2. 모델 설계: 합성곱(Convolution)과 Pooling 레이어를 포함함 CNN 모델의 설계도를 직접 코드로 작성
3. 손실 함수 & 옵티마이저 정의: 모델의 오답노트 역할을 할 손실 함수와, 똑똑한 수정 도구인 옵티마이저를 설정
4. 모델 학습: 준비된 데이터를 모델에 반복적으로 보여주며 가중치 업데이트
5. 모델 평가: 학습이 끝난 모델이 처음 보는 테스트 데이터에 대해 얼마나 정확하게 분류하는지 성능을 확인
## 1단계 - 데이터 준비
### torchvision으로 데이터셋 불러오기
- torchvision
  - PyTorch에서 이미지 관련 작업을 편리하게 할 수 있도록 도와주는 라이브러리
  - CIFAL-10, MNIST 등 유명한 데이터셋을 쉽게 다운로드하고, 이미지 변환(전처리) 기능을 제공
- DataLoader의 역할
  - 전체 데이터셋을 mini-batch 단위로 묶어줌
  - 데이터 순서를 무작위로 섞어주는(shuffle=True) 등, 모델이 효율적으로 학습할 수 있도록 데이터를 공급하는 역할
### 이미지 전처리(Transform)
- 컴퓨터는 이미지를 픽셀 값의 집합으로 인식
- 모델이 이 숫자들을 더 잘 이해하고 학습하도록 두가지 중요한 전처리를 수행
1. transforms.ToTensor()
   - 일반적인 이미지 파일(PIL Image)을 PyTorch가 다룰 수 있는 Tensor 형태로 변환
   - 이 과정에서 각 픽셀 값을 0 ~ 255 범위에서 0.0 ~ 1.0 범위로 자동으로 조정(스케일링)
2. transform.Normalize()
   - 0.0 ~ 1.0 범위의 픽셀 값을 평균이 0, 표준편차가 1에 가깝도록 정규화(-1.0 ~ 1.0 범위로 조정)
   - 이는 데이터의 분포를 안정적으로 만들어 학습 속도와 성능을 향상시키는 효과
## 2단계 - CNN 모델 설계
### 1-1 특징 추출기(합성곱 레이어)
- CNN의 핵심 연장 1 - 합성곱(Convolution)
  - 역할: 이미지의 특징을 추출하는 가장 핵심적인 부분
    - 특징이란? 이미지의 성격을 규정하는 작은 패턴(수직선, 수평선, 특정 색상, 질감 등)을 의미
  - 핵심 구성 요소
    - 입력 이미지: 컴퓨터에게는 숫자로 이루어진 Grid(컬러 이미지는 R, G, B 3개의 격자가 겹쳐있는 형태)
    - Filter/Kernel: 특징을 찾아내는 역할을 하는 특징 탐지기와 같은 작은 행렬
    - Feature Map: 필터가 이미지 전체를 훑고 지나간 결과물로, 특정 특징이 원본이미지 어디에 분포하는지를 보여주는 특징 지도
- 합성곱의 동작 원리 - 특징 도장 찍기
  - 원리: 필터가 이미지 위를 이동하며, 겹치는 영역의 픽셀 값과 필터의 가중치를 곱하고 모두 더함(합성곱 연산)
  - 동작 과정
    1. 필터가 이미지의 좌측 상단부터 정해진 간격(Stride)으로 이동
    2. 각 위치에서 필터의 가중치와 이미지 픽셀 값을 원소별로 곱한 후, 그 결과를 모두 합산
    3. 이 합산된 단일 값이 특징 맵의 한 픽셀을 이룸
    4. 이 과정을 이미지 전체에 대해 반복하면, 하나의 필터로부터 하나의 특징 맵이 생성
  - 만약 필터가 64개라면, 각각 다른 특징을 감지하는 64개의 다른 특징 맵이 만들어짐
- 합성곱 코드 구현(nn.Conv2d)
  - PyTorch에서는 nn.Conv2d를 사용하여 2D 이미지에 대한 합성곱 계층 정의
  - nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)
    - in_channels=3: 입력 이미지의 채널 수(RGB)
    - out_channels=6: 사용할 필터의 개수, 생성될 특징 맵의 개수
    - kernel_size=5: 필터의 크기(5 X 5)
  - 실습 코드에서는 첫번째 합성곱 층에서는 3채널 이미지를 입력받아 6개의 특징 맵을, 두번째 층에서는 6개의 특징 맵을 입력받아 16개의 더 복잡한 특징 맵을 추출
```python
self.conv1 = nn.Conv2d(3, 6, 5)
self.conv2 = nn.Conv2d(6, 16, 5)
```
### 1-2 특징 추출기(풀링 레이어)
- CNN의 핵심 연장 2 - Pooling
  - 정의: 합성곱 연산을 통해 얻은 특징 맵의 크기를 줄이는(Downsampling) 과정
  - 목적
    - 연산 효율성: 특징 맵의 크기를 줄여 다음 계층에서 처리해야 할 파라미터 수를 감소시킴
    - 과적합 방지: 중요한 특징만 남기고 사소한 변화는 무시하여, 모델이 이미지의 미세한 노이즈나 위치 변화에 과도하게 민감해지는 것을 방지
  - 동작 원리(Max Pooling)
    1. 특징 맵을 정해진 크기의 구역으로 나눔
    2. 각 구역에서 가장 큰 값 하나만 남기고 나머지는 버림
- 풀링 코드 구현(nn.MaxPool2d)
  - PyTorch에서는 nn.MaxPool2d를 사용하여 최대 풀링 계층을 정의
  - nn.MaxPool2d(kernel_size=2, stride=2)의 의미
    - kernel_size=2: 2 X 2 크기의 윈도우 안에서 최대값을 찾음
    - stride=2: 윈도우를 2칸씩 이동시킴
    - 결과적으로 특징 맵의 가로, 세로 크기가 절반으로 줄어듦
  - 실습 코드에서는 각 합성곱 연산 후에 이 풀링 레이어를 적용하여 특징 맵의 크기를 점진적으로 줄여나감
```python
self.pool = nn.MaxPool2d(2, 2)
```
### 1-3 특징 추출기(계층적 특징 추출)
- CNN은 합성곱 층을 여러개 쌓아 올림으로써 더욱 복잡하고 추상적인 특징을 학습
- 낮은 계층(초반 레이어): 이미지의 가장 기초적인 특징인 선, 모서리, 색상 등을 감지
- 중간 계층: 낮은 계층에서 추출된 특징들을 조합하여 눈, 코, 입, 바퀴와 같은 더 복잡한 형태를 학습
- 높은 계층(후반 레이어): 중간 계층의 특징들을 다시 조합하여 사람의 얼굴, 자동차의 형태와 같은 매우 추상적이고 고수준의 특징을 인식하게 됨
- 이처럼 CNN은 단순한 패턴에서 복잡한 패턴으로, 점진적이고 계층적으로 특징을 학습하기 때문에 이미지 인식에 매우 강력한 성능을 보임
### 2 분류기(평탄화 & 완전 연결 레이어)
- 완전 연결 레이어(nn.Linear)
  - 역할: CNN의 마지막 단계에서 추출된 모든 특징들을 종합하여 이미지가 어떤 클래스에 속할지 최종적으로 분류하는 역할
  - 과정
    - 합성곱과 풀링을 커쳐 압축된 특징 맵은 1차원 벡터로 평탄화
    - 이 벡터가 우리가 이전에 배웠던 MLP(완전 연결 레이어)의 입력으로 들어가, 최종적으로 10개 클래스에 대한 예측 점수를 출력\
  - 실습 코드
```python
self.fc1 = nn.Linear(16 * 5 * 5, 120)
self.fc2 = nn.Linear(120, 84)
self.fc3 = nn.Linear(84, 10)
```
- 합성곱 신경망의 수겅
  - 합성곱 층 -> 활성화 함수 적용 -> 풀링 층이 반복된 후에 완전히 상호 연결된 결합 은닉층이 추가된 형태가 되며, 최종적으로 출력층이 배치됨
## 3 & 4단계 - 모델 학습
### 손실 함수와 옵티마이저
- 손실 함수(nn.CrossEntropyLoss)
  - 분류 문제에서 가장 널리 사용되는 손실 함수
  - 모델이 출력한 10개 클래스에 대한 예측 점수와 실제 정답 레이블을 비교하여, 얼마나 틀렸는지를 하나의 숫자로 계산
- 옵티마이저(optim.SGD)
  - 계산된 손실을 줄이는 방향으로 모델의 가중치를 업데이트하는 역할
  - SGD는 경사 하강법의 가장 기본적인 형태로, 손실의 기울기를 따라 파라미터를 조금씩 수정해 나감
  - momentum은 이 과정에 관성을 부여하여 더 빠르고 안정적으로 최적점에 도달하도록 도움
### 학습 루프
- 모델 훈련은 다음 과정을 수업이 반복(Epoch)하는 것
- 이 과정을 통해 모델은 점차 오답을 줄여나가며 똑똑해짐
1. DataLoader에서 미니배치 데이터를 가져옴
2. 기울기 초기화: optimizer.zero_grad()
3. 순전파: outputs = net(inputs)
4. 손실 계산: loss = criterion(outputs, labels)
5. 역전파: loss.backward()
6. 가중치 업데이트: optimizer.step()
## 5단계 - 모델 평가
### 테스트 데이터로 성능 검증
- 테스트 데이터가 필요한 이유
  - 모델이 푼련 데이터를 단순히 암기했을 수 있음(과적합)
  - 따라서 학습에 전혀 사용되지 않은 테스트 데이터로 평가해야 모델의 진짜 일반화 성능을 알 수 있음
- 평가 과정
  - 테스트 데이터를 모델에 입력하여 예측값 얻음
  - torch.max 함수를 사용해 모델이 가장 높게 예측한 클래스를 선택
  - 이 예측값과 실제 정답을 비교하여 Accuracy 계산
- with torch.no_grad()
  - 평가시에는 기울기를 계산할 필요가 없으므로, 이 구문 안에서 코드를 실행하면 불필요한 연산을 막아 메모리 사요량을 줄이고 속도를 높일 수 있음
### GPU에서 학습
- GPU 사용 이유
  - CNN은 수많은 행렬곱 연산을 수행하기 때문에 CPU로는 학습에 매우 오랜 시간이 걸림
  - GPU는 이러한 병렬 연산에 특화되어 있어 학습 속도를 비약적으로 향상시킬 수 있음
- PyTorch에서 GPU 사용하기
  1. 사용가능한 장치 설정
```python
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
```
  2. 모델을 해당 장치로 보냄
```python
net.to(device)
```
  3. 학습 루프 안에서 데이터 텐서도 동일한 장치로 보냄
```python
inputs, labels = data[0].to(device), data[1].to(device)
```